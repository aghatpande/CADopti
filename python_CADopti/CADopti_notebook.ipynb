{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Assembly Detection with CADopti\n",
    "\n",
    "**Author:** Ambarish S. Ghatpande  \n",
    "**Date:** 2024-09-02  \n",
    "**TOC:** macro  \n",
    "**TOC Levels:** 2\n",
    "\n",
    "This Jupyter notebook provides a comprehensive implementation of the `CADopti` function, which is designed to detect cell assemblies in spike train data using a multi-step analysis process. The notebook leverages advanced statistical methods and parallel processing to efficiently identify and refine potential assemblies across different temporal resolutions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The notebook is divided into several sections, each corresponding to a key step in the cell assembly detection pipeline:\n",
    "\n",
    "1. **Initialization and Preprocessing**: This section initializes the parameters and preprocesses the input spike train data by removing NaNs and padding the spike times to ensure consistent lengths across all neurons.\n",
    "\n",
    "2. **Matrix Binning**: Spike train data is binned at various temporal resolutions, and the number of pairwise comparisons required for assembly detection is calculated.\n",
    "\n",
    "3. **First Order Assembly Detection**: The notebook identifies potential first-order assemblies by evaluating pairwise neuron interactions using parallel processing. A Holm-Bonferroni correction is applied to control for multiple comparisons.\n",
    "\n",
    "4. **Higher Order Assembly Detection**: This section extends the assembly detection process to identify higher-order assemblies. The notebook iteratively adds new neurons to existing assemblies and prunes less significant assemblies to refine the results.\n",
    "\n",
    "5. **Assembly Refinement and Final Output**: The identified assemblies are further refined by comparing them across different temporal resolutions, and the final assembly structures are outputted along with their associated statistical parameters.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook assumes familiarity with Python programming, spike train analysis, and statistical methods for multiple comparisons. It also requires the following Python libraries:\n",
    "\n",
    "- `numpy`\n",
    "- `scipy`\n",
    "- `multiprocessing`\n",
    "- `itertools`\n",
    "\n",
    "## How to Use\n",
    "\n",
    "Simply run the cells in sequence to execute the `CADopti` function on your spike train data. The function's output will include the detected assemblies and associated statistical information.\n",
    "\n",
    "For further details on the `CADopti` function and the methods used in this notebook, refer to the relevant sections in the code and the accompanying comments.\n",
    "\n",
    "## Contact Information\n",
    "\n",
    "For any questions or further assistance, please contact **A.S. Ghatpande** at `aghatpande@gmail.com`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Cell: Importing the necessary libraries\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import multiprocessing as mp\n",
    "from itertools import combinations\n",
    "\n",
    "# Import helper functions\n",
    "from FindAssemblies_recursive_prepruned import find_assemblies_recursive_prepruned\n",
    "from TestPair_ref import test_pair_ref\n",
    "from assemblies_across_bins import assemblies_across_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Cell: Defining the process_pair function\n",
    "def process_pair(args):\n",
    "    w1, w2, binM, MaxLags, BinSizes, Dc, ref_lag = args\n",
    "    assemblybin = [None] * len(BinSizes)\n",
    "    p_by_bin = []\n",
    "    for gg in range(len(BinSizes)):\n",
    "        assemblybin[gg] = find_assemblies_recursive_prepruned(\n",
    "            np.vstack((binM[gg][w1, :], binM[gg][w2, :])),\n",
    "            w1, w2, MaxLags[gg], Dc, ref_lag\n",
    "        )\n",
    "        if assemblybin[gg] is not None:\n",
    "            p_by_bin.append(assemblybin[gg]['pr'][-1])\n",
    "            assemblybin[gg]['bin'] = BinSizes[gg]\n",
    "        else:\n",
    "            print(f\"find_assemblies_recursive_prepruned returned None for w1={w1}, w2={w2}, binSize={BinSizes[gg]}\")\n",
    "            p_by_bin.append(float('inf'))  # Assign a high p-value if the result is None\n",
    "\n",
    "    b = np.argmin(p_by_bin)\n",
    "    return assemblybin[b], p_by_bin[b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons: 50\n",
      "Number of spikes per neuron:\n",
      "[6722, 6551, 6631, 6631, 6765, 6679, 6617, 6594, 6568, 6599, 7061, 7301, 6727, 7350, 6899, 7746, 7616, 7695, 7723, 7747, 8945, 9033, 9134, 9133, 9003, 6403, 6335, 6350, 6218, 6479, 6333, 6458, 6383, 6324, 6392, 6310, 6332, 6457, 6306, 6372, 6476, 6272, 6305, 6334, 6332, 6367, 6291, 6357, 6289, 6374]\n"
     ]
    }
   ],
   "source": [
    "# copied from Tutorial_CADopti.ipynb, since needed to run this notebook independently for troubleshooting\n",
    "# Load data from the .mat file\n",
    "from scipy import io as sio\n",
    "mat_data = sio.loadmat('Data.mat')\n",
    "\n",
    "# Uncomment the following lines if you need to troubleshoot loading the data\n",
    "# print(\"Keys in Data.mat:\", mat_data.keys())\n",
    "# print(\"spM shape:\", mat_data['spM'].shape)\n",
    "# print(\"spM data type:\", mat_data['spM'].dtype)\n",
    "# print(\"Sample of spM (first 5 rows, first 10 columns):\")\n",
    "# print(mat_data['spM'][:5, :10])\n",
    "\n",
    "# Assign spM correctly\n",
    "spM = mat_data['spM']\n",
    "\n",
    "# Convert spM to a list of spike times, removing NaNs\n",
    "spike_times = [row[~np.isnan(row)] for row in spM]\n",
    "\n",
    "# Print some statistics to check if the data is correct\n",
    "print(\"Number of neurons:\", len(spike_times))\n",
    "print(\"Number of spikes per neuron:\")\n",
    "print([len(spikes) for spikes in spike_times])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from Tutorial_CADopti.ipynb, since needed to run this notebook independently for troubleshooting\n",
    "# Check if there are any empty spike trains\n",
    "empty_trains = [i for i, spikes in enumerate(spike_times) if len(spikes) == 0]\n",
    "if empty_trains:\n",
    "    print(f\"Empty spike trains found at indices: {empty_trains}\")\n",
    "\n",
    "# Check for NaNs, Infinities, and Identical Values\n",
    "for i, spikes in enumerate(spike_times):\n",
    "    if np.isnan(spikes).any():\n",
    "        print(f\"NaNs found in spike train {i}\")\n",
    "    if np.isinf(spikes).any():\n",
    "        print(f\"Infinities found in spike train {i}\")\n",
    "    if len(np.unique(spikes)) == 1:\n",
    "        print(f\"Identical spike times found in spike train {i}: {spikes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from Tutorial_CADopti.ipynb, since needed to run this notebook independently for troubleshooting\n",
    "# Calculate and print inter-spike intervals for each spike train\n",
    "for i, spikes in enumerate(spike_times):\n",
    "    if len(spikes) > 1:\n",
    "        inter_spike_intervals = np.diff(spikes)\n",
    "        print(f\"Spike train {i} inter-spike intervals (min, max, mean): {np.min(inter_spike_intervals)}, {np.max(inter_spike_intervals)}, {np.mean(inter_spike_intervals)}\")\n",
    "    else:\n",
    "        print(f\"Spike train {i} has fewer than 2 spikes, cannot compute intervals.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "MaxLags = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]  # 10 is the maximum lag for each bin size\n",
    "BinSizes = [0.015, 0.025, 0.04, 0.06, 0.085, 0.15, 0.25, 0.4, 0.6, 0.85, 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Cell: Defining the CADopti function\n",
    "def CADopti(spike_times, MaxLags, BinSizes, ref_lag=None, alph=None, No_th=None, O_th=None, bytelimit=None):\n",
    "    # Function Documentation and Initialization of Default Parameters\n",
    "    if ref_lag is None:\n",
    "        ref_lag = 2\n",
    "    if alph is None:\n",
    "        alph = 0.05\n",
    "    if No_th is None:\n",
    "        No_th = 0  # no limitation on the number of assembly occurrences\n",
    "    if O_th is None:\n",
    "        O_th = float('inf')  # no limitation on the assembly order (=number of elements in the assembly)\n",
    "    if bytelimit is None:\n",
    "        bytelimit = float('inf')  # no limitation on assembly dimension\n",
    "\n",
    "    # Initialize variables and pre-process spike_times\n",
    "    nneu = len(spike_times)  # number of units\n",
    "    testit = np.ones(len(BinSizes))\n",
    "    binM = [None] * len(BinSizes)\n",
    "    number_tests = 0\n",
    "\n",
    "    # Remove NaNs and get valid spike times for each neuron\n",
    "    spike_times = [neuron[~np.isnan(neuron)] for neuron in spike_times]\n",
    "    \n",
    "    # After removing NaNs, pad spike times to equal lengths\n",
    "    max_spikes = max(len(spikes) for spikes in spike_times)\n",
    "    padded_spike_times = [np.pad(spikes, (0, max_spikes - len(spikes)), \n",
    "                             mode='constant', constant_values=np.nan) \n",
    "                      for spikes in spike_times]\n",
    "\n",
    "    # Check input data after processing for empty arrays after removing NaNs\n",
    "    if not padded_spike_times or any(len(spikes) == 0 for spikes in padded_spike_times):\n",
    "        raise ValueError(\"Invalid input: spike_times is empty or contains empty arrays after processing\")\n",
    "    \n",
    "    # Calculate the minimum interval between spikes and overall min and max times\n",
    "    int_val = np.min([np.min(np.diff(times)) for times in padded_spike_times if len(times) > 1])\n",
    "    min_val = np.min([np.min(times) for times in padded_spike_times if len(times) > 0])\n",
    "    max_val = np.max([np.max(times) for times in padded_spike_times if len(times) > 0])\n",
    "\n",
    "    # Validations and checks\n",
    "    if not np.isfinite(int_val):\n",
    "        raise ValueError(\"Couldn't compute a valid inter-spike interval\")\n",
    "    \n",
    "    if min_val >= max_val:\n",
    "        raise ValueError(f\"min value ({min_val}) is greater than or equal to max value ({max_val})\")\n",
    "    \n",
    "    if int_val == 0:\n",
    "        raise ValueError(\"int_val is zero\")\n",
    "    \n",
    "    print(f\"Minimum inter-spike interval: {int_val}\")\n",
    "    print(f\"Min time: {min_val}, Max time: {max_val}\")\n",
    "    \n",
    "    # matrix binning at all bins\n",
    "    for gg in range(len(BinSizes)):\n",
    "        bin_size = BinSizes[gg]\n",
    "        tb = np.arange(min_val, max_val + bin_size, bin_size)\n",
    "    \n",
    "        binM[gg] = np.zeros((nneu, len(tb) - 1), dtype=np.uint8)\n",
    "        number_tests += nneu * (nneu - 1) * (2 * MaxLags[gg] + 1) // 2\n",
    "    \n",
    "        for n in range(nneu):\n",
    "            binM[gg][n, :], _ = np.histogram(padded_spike_times[n][~np.isnan(padded_spike_times[n])], tb)\n",
    "        \n",
    "        assembly = {'bin': [{'n': [], 'bin_edges': tb} for _ in range(len(BinSizes))]}\n",
    "        \n",
    "        if binM[gg].shape[1] - MaxLags[gg] < 100:\n",
    "            print(f'Warning: testing bin size={int_val}. The time series is too short, consider taking a longer portion of spike train or diminish the bin size to be tested')\n",
    "            testit[gg] = 0\n",
    "\n",
    "    # Detecting First Order Assemblies\n",
    "    print('order 1')\n",
    "    Assemblies_all_orders = []\n",
    "    O = 1\n",
    "    Dc = 100  # length (in # bins) of the segments in which the spike train is divided to compute #abba variance (parameter k).\n",
    "\n",
    "    assembly_selected_xy = []\n",
    "    p_values = []\n",
    "\n",
    "    # First order assembly\n",
    "    print('order 1')\n",
    "    assembly_selected_xy = []\n",
    "    p_values = []\n",
    "        \n",
    "    # Prepare arguments for parallel processing\n",
    "    pair_args = [\n",
    "            (w1, w2, binM, MaxLags, BinSizes, Dc, ref_lag)\n",
    "            for w1, w2 in combinations(range(nneu), 2)\n",
    "        ]\n",
    "        \n",
    "    # Use multiprocessing to parallelize the computation\n",
    "    with mp.Pool() as pool:\n",
    "            results = pool.map(process_pair, pair_args)\n",
    "        \n",
    "    # Process the results\n",
    "    for result, p_value in results:\n",
    "        if result is not None:\n",
    "            assembly_selected_xy.append(result)\n",
    "            p_values.append(p_value)\n",
    "        \n",
    "    if not assembly_selected_xy:\n",
    "        raise ValueError(\"No valid assemblies found. Check the input data and parameters.\")\n",
    "        \n",
    "    assembly_selected = assembly_selected_xy\n",
    "        \n",
    "    # Holm-Bonferroni correction\n",
    "    x = np.arange(1, len(p_values) + 1)\n",
    "    p_values = np.sort(p_values)\n",
    "    p_values_alpha = alph / (number_tests + 1 - x)\n",
    "        \n",
    "    ANfo = np.zeros((nneu, nneu))\n",
    "        \n",
    "    # Initialize HBcorrected_p before using it\n",
    "    aus = np.where((p_values - p_values_alpha) < 0)[0]\n",
    "    HBcorrected_p = 0 if len(aus) == 0 else p_values[aus[-1]]\n",
    "        \n",
    "    for oo in range(len(assembly_selected) - 1, -1, -1):\n",
    "        if assembly_selected[oo]['pr'][-1] > HBcorrected_p:\n",
    "            assembly_selected.pop(oo)\n",
    "        else:\n",
    "            ANfo[assembly_selected[oo]['elements'][0], assembly_selected[oo]['elements'][1]] = 1\n",
    "        \n",
    "    Assemblies_all_orders = [assembly_selected]\n",
    "\n",
    "    # Detecting Higher Order Assemblies\n",
    "    # Higher orders\n",
    "    Oincrement = 1\n",
    "    while Oincrement and O < (O_th - 1):\n",
    "        O += 1\n",
    "        print(f'order {O}')\n",
    "        Oincrement = 0\n",
    "        assembly_selected_aus = []\n",
    "        xx = 0  # Python uses 0-based indexing\n",
    "        \n",
    "        for w1 in range(len(assembly_selected)):\n",
    "            # bin at which to test w1\n",
    "            ggg = BinSizes.index(assembly_selected[w1]['bin'])\n",
    "        \n",
    "            # element to test with w1\n",
    "            w1_elements = assembly_selected[w1]['elements']\n",
    "            w2_to_test = np.where(ANfo[w1_elements, :] == 1)[1]  # Using numpy for efficiency\n",
    "            w2_to_test = w2_to_test[~np.isin(w2_to_test, w1_elements)]  # Remove elements already in the assembly\n",
    "            w2_to_test = np.unique(w2_to_test)\n",
    "        \n",
    "            for w2 in w2_to_test:\n",
    "                spikeTrain2 = binM[ggg][w2, :]\n",
    "                assemblybin_aus = test_pair_ref(assembly_selected[w1], spikeTrain2, w2, MaxLags[ggg], Dc, ref_lag)\n",
    "                p_values.append(assemblybin_aus['pr'][-1])\n",
    "                number_tests += 2 * MaxLags[ggg] + 1\n",
    "                if assemblybin_aus['pr'][-1] < HBcorrected_p:\n",
    "                    assembly_selected_aus.append(assemblybin_aus)\n",
    "                    assembly_selected_aus[-1]['bin'] = BinSizes[ggg]\n",
    "                    xx += 1\n",
    "                    Oincrement = 1\n",
    "\n",
    "        if Oincrement:\n",
    "            # Pruning within the same size\n",
    "            na = len(assembly_selected_aus)\n",
    "            nelement = len(assembly_selected_aus[0]['elements'])\n",
    "            selection = np.full((na, nelement + 2), np.nan)\n",
    "            assembly_final = [None] * na\n",
    "            nns = 0\n",
    "\n",
    "            for i in range(na):\n",
    "                elem = sorted(assembly_selected_aus[i]['elements'])\n",
    "                ism = np.all(selection[:, :nelement] == elem, axis=1)\n",
    "                if not np.any(ism):\n",
    "                    assembly_final[nns] = assembly_selected_aus[i]\n",
    "                    selection[nns, :nelement] = elem\n",
    "                    selection[nns, nelement] = assembly_selected_aus[i]['pr'][-1]\n",
    "                    selection[nns, nelement + 1] = i\n",
    "                    nns += 1\n",
    "                else:\n",
    "                    indx = np.where(ism)[0][0]\n",
    "                    if selection[indx, nelement] > assembly_selected_aus[i]['pr'][-1]:\n",
    "                        assembly_final[indx] = assembly_selected_aus[i]\n",
    "                        selection[indx, nelement] = assembly_selected_aus[i]['pr'][-1]\n",
    "                        selection[indx, nelement + 1] = i\n",
    "\n",
    "            assembly_final = [a for a in assembly_final if a is not None]\n",
    "            assembly_selected = assembly_final\n",
    "            Assemblies_all_orders.append(assembly_final)\n",
    "\n",
    "        # Holm-Bonferroni correction\n",
    "        x = np.arange(1, len(p_values) + 1)\n",
    "        p_values = np.sort(p_values)\n",
    "        p_values_alpha = alph / (number_tests + 1 - x)\n",
    "        aus = np.where((p_values - p_values_alpha) < 0)[0]\n",
    "        HBcorrected_p = 0 if len(aus) == 0 else p_values[aus[-1]]\n",
    "\n",
    "        for o in range(len(Assemblies_all_orders)):\n",
    "            Assemblies_all_orders[o] = [a for a in Assemblies_all_orders[o] if a['pr'][-1] <= HBcorrected_p]\n",
    "\n",
    "        # Pruning between different assembly sizes\n",
    "        Element_template = []\n",
    "        for assembly in Assemblies_all_orders[-1]:\n",
    "            Element_template.append(assembly['elements'])\n",
    "\n",
    "        for o in range(len(Assemblies_all_orders) - 2, -1, -1):\n",
    "            new_assemblies = []\n",
    "            for assembly in Assemblies_all_orders[o]:\n",
    "                if not any(set(assembly['elements']).issubset(set(template)) for template in Element_template):\n",
    "                    new_assemblies.append(assembly)\n",
    "                    Element_template.append(assembly['elements'])\n",
    "            Assemblies_all_orders[o] = new_assemblies\n",
    "\n",
    "        # Reformat dividing by bins\n",
    "        assembly = {'bin': [{} for _ in range(len(BinSizes))]}\n",
    "        for o, order_assemblies in enumerate(Assemblies_all_orders):\n",
    "            for oo, a in enumerate(order_assemblies):\n",
    "                bx = BinSizes.index(a['bin'])\n",
    "                if 'n' not in assembly['bin'][bx]:\n",
    "                    assembly['bin'][bx]['n'] = []\n",
    "                assembly['bin'][bx]['n'].append(a)\n",
    "\n",
    "        # Remove empty bins\n",
    "        assembly['bin'] = [b for b in assembly['bin'] if b]\n",
    "\n",
    "        # Add parameters to assembly\n",
    "        assembly['parameters'] = {\n",
    "            'alph': alph,\n",
    "            'Dc': Dc,\n",
    "            'No_th': No_th,\n",
    "            'O_th': O_th,\n",
    "            'bytelimit': bytelimit,\n",
    "            'ref_lag': ref_lag\n",
    "        }\n",
    "\n",
    "    # Return statement inside the function\n",
    "    As_across_bins, As_across_bins_index = assemblies_across_bins(assembly, BinSizes)\n",
    "    return As_across_bins, As_across_bins_index, assembly, Assemblies_all_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Couldn't compute a valid inter-spike interval",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fourth Cell: Running the CADopti function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m As_across_bins, As_across_bins_index, assembly, Assemblies_all_orders \u001b[38;5;241m=\u001b[39m \u001b[43mCADopti\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMaxLags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBinSizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 41\u001b[0m, in \u001b[0;36mCADopti\u001b[1;34m(spike_times, MaxLags, BinSizes, ref_lag, alph, No_th, O_th, bytelimit)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Validations and checks\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(int_val):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt compute a valid inter-spike interval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_val \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_val:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin value (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is greater than or equal to max value (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Couldn't compute a valid inter-spike interval"
     ]
    }
   ],
   "source": [
    "# Fourth Cell: Running the CADopti function\n",
    "As_across_bins, As_across_bins_index, assembly, Assemblies_all_orders = CADopti(spike_times, MaxLags, BinSizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Tutorial_CADopti.ipynb; visualize the results\n",
    "\n",
    "# Visualization\n",
    "nneu = len(spike_times)  # number of recorded units\n",
    "display = 'raw'  # or 'clustered'\n",
    "Amatrix, Binvector, Unit_order, As_order = assembly_assignment_matrix(As_across_bins, nneu, BinSizes, display)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    " plt.imshow(Amatrix)\n",
    "\n",
    "plt.title('Assembly Assignment Matrix')\n",
    "\n",
    "plt.xlabel('Assembly')\n",
    "\n",
    "plt.ylabel('Neuron')\n",
    "\n",
    " plt.colorbar(label='Assignment')\n",
    "\n",
    "plt.savefig('assembly_assignment_matrix.png')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# Assembly Activation\n",
    "lagChoice = 'duration'\n",
    "act_count = 'full'\n",
    "assembly_activity = assembly_activity_function(As_across_bins, assembly, spike_times, BinSizes, lagChoice, act_count)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, activity in enumerate(assembly_activity):\n",
    "    plt.subplot(len(assembly_activity), 1, i+1)\n",
    "    plt.plot(activity[:, 0], activity[:, 1])\n",
    "    plt.title(f'Assembly {i+1} Activity')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Activity')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('assembly_activity.png')\n",
    "    plt.close()\n",
    "\n",
    "# Print summary of detected assemblies\n",
    "print(\"\\nDetected Assemblies:\")\n",
    "for i, assembly in enumerate(As_across_bins):\n",
    "    print(f\"Assembly {i+1}:\")\n",
    "    print(f\"  Elements: {assembly['elements']}\")\n",
    "    print(f\"  Bin size: {assembly['bin']}\")\n",
    "    print(f\"  Lags: {assembly['lag']}\")\n",
    "    print(f\"  p-values: {assembly['pr']}\")\n",
    "    print(f\"  Occurrences: {assembly['Noccurrences']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythoncadopti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
