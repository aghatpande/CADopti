{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Assembly Detection with CADopti\n",
    "\n",
    "**Author:** Ambarish S. Ghatpande  \n",
    "**Date:** 2024-09-02  \n",
    "**TOC:** macro  \n",
    "**TOC Levels:** 2\n",
    "\n",
    "This Jupyter notebook provides a comprehensive implementation of the `CADopti` function, which is designed to detect cell assemblies in spike train data using a multi-step analysis process. The notebook leverages advanced statistical methods and parallel processing to efficiently identify and refine potential assemblies across different temporal resolutions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The notebook is divided into several sections, each corresponding to a key step in the cell assembly detection pipeline:\n",
    "\n",
    "1. **Initialization and Preprocessing**: This section initializes the parameters and preprocesses the input spike train data by removing NaNs and padding the spike times to ensure consistent lengths across all neurons.\n",
    "\n",
    "2. **Matrix Binning**: Spike train data is binned at various temporal resolutions, and the number of pairwise comparisons required for assembly detection is calculated.\n",
    "\n",
    "3. **First Order Assembly Detection**: The notebook identifies potential first-order assemblies by evaluating pairwise neuron interactions using parallel processing. A Holm-Bonferroni correction is applied to control for multiple comparisons.\n",
    "\n",
    "4. **Higher Order Assembly Detection**: This section extends the assembly detection process to identify higher-order assemblies. The notebook iteratively adds new neurons to existing assemblies and prunes less significant assemblies to refine the results.\n",
    "\n",
    "5. **Assembly Refinement and Final Output**: The identified assemblies are further refined by comparing them across different temporal resolutions, and the final assembly structures are outputted along with their associated statistical parameters.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook assumes familiarity with Python programming, spike train analysis, and statistical methods for multiple comparisons. It also requires the following Python libraries:\n",
    "\n",
    "- `numpy`\n",
    "- `scipy`\n",
    "- `multiprocessing`\n",
    "- `itertools`\n",
    "\n",
    "## How to Use\n",
    "\n",
    "Simply run the cells in sequence to execute the `CADopti` function on your spike train data. The function's output will include the detected assemblies and associated statistical information.\n",
    "\n",
    "For further details on the `CADopti` function and the methods used in this notebook, refer to the relevant sections in the code and the accompanying comments.\n",
    "\n",
    "## Contact Information\n",
    "\n",
    "For any questions or further assistance, please contact **A.S. Ghatpande** at `aghatpande@gmail.com`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Cell: Importing the necessary libraries\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import multiprocessing as mp\n",
    "from itertools import combinations\n",
    "\n",
    "# Import helper functions\n",
    "from FindAssemblies_recursive_prepruned import find_assemblies_recursive_prepruned\n",
    "from TestPair_ref import test_pair_ref\n",
    "from assemblies_across_bins import assemblies_across_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Cell: Defining the process_pair function\n",
    "def process_pair(args):\n",
    "    w1, w2, binM, MaxLags, BinSizes, Dc, ref_lag = args\n",
    "    assemblybin = [None] * len(BinSizes)\n",
    "    p_by_bin = []\n",
    "    for gg in range(len(BinSizes)):\n",
    "        assemblybin[gg] = find_assemblies_recursive_prepruned(\n",
    "            np.vstack((binM[gg][w1, :], binM[gg][w2, :])),\n",
    "            w1, w2, MaxLags[gg], Dc, ref_lag\n",
    "        )\n",
    "        if assemblybin[gg] is not None:\n",
    "            p_by_bin.append(assemblybin[gg]['pr'][-1])\n",
    "            assemblybin[gg]['bin'] = BinSizes[gg]\n",
    "        else:\n",
    "            print(f\"find_assemblies_recursive_prepruned returned None for w1={w1}, w2={w2}, binSize={BinSizes[gg]}\")\n",
    "            p_by_bin.append(float('inf'))  # Assign a high p-value if the result is None\n",
    "\n",
    "    b = np.argmin(p_by_bin)\n",
    "    return assemblybin[b], p_by_bin[b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Cell: Defining the CADopti function\n",
    "def CADopti(spike_times, MaxLags, BinSizes, ref_lag=None, alph=None, No_th=None, O_th=None, bytelimit=None):\n",
    "    # Function Documentation and Initialization of Default Parameters\n",
    "    if ref_lag is None:\n",
    "        ref_lag = 2\n",
    "    if alph is None:\n",
    "        alph = 0.05\n",
    "    if No_th is None:\n",
    "        No_th = 0  # no limitation on the number of assembly occurrences\n",
    "    if O_th is None:\n",
    "        O_th = float('inf')  # no limitation on the assembly order (=number of elements in the assembly)\n",
    "    if bytelimit is None:\n",
    "        bytelimit = float('inf')  # no limitation on assembly dimension\n",
    "\n",
    "    # Initialize variables and pre-process spike_times\n",
    "    nneu = len(spike_times)  # number of units\n",
    "    testit = np.ones(len(BinSizes))\n",
    "    binM = [None] * len(BinSizes)\n",
    "    number_tests = 0\n",
    "\n",
    "    # Remove NaNs and get valid spike times for each neuron\n",
    "    spike_times = [neuron[~np.isnan(neuron)] for neuron in spike_times]\n",
    "    \n",
    "    # After removing NaNs, pad spike times to equal lengths\n",
    "    max_spikes = max(len(spikes) for spikes in spike_times)\n",
    "    padded_spike_times = [np.pad(spikes, (0, max_spikes - len(spikes)), \n",
    "                             mode='constant', constant_values=np.nan) \n",
    "                      for spikes in spike_times]\n",
    "\n",
    "    # Check input data after processing for empty arrays after removing NaNs\n",
    "    if not padded_spike_times or any(len(spikes) == 0 for spikes in padded_spike_times):\n",
    "        raise ValueError(\"Invalid input: spike_times is empty or contains empty arrays after processing\")\n",
    "    \n",
    "    # Calculate the minimum interval between spikes and overall min and max times\n",
    "    int_val = np.min([np.min(np.diff(times)) for times in padded_spike_times if len(times) > 1])\n",
    "    min_val = np.min([np.min(times) for times in padded_spike_times if len(times) > 0])\n",
    "    max_val = np.max([np.max(times) for times in padded_spike_times if len(times) > 0])\n",
    "\n",
    "    # Validations and checks\n",
    "    if not np.isfinite(int_val):\n",
    "        raise ValueError(\"Couldn't compute a valid inter-spike interval\")\n",
    "    \n",
    "    if min_val >= max_val:\n",
    "        raise ValueError(f\"min value ({min_val}) is greater than or equal to max value ({max_val})\")\n",
    "    \n",
    "    if int_val == 0:\n",
    "        raise ValueError(\"int_val is zero\")\n",
    "    \n",
    "    print(f\"Minimum inter-spike interval: {int_val}\")\n",
    "    print(f\"Min time: {min_val}, Max time: {max_val}\")\n",
    "    \n",
    "    # matrix binning at all bins\n",
    "    for gg in range(len(BinSizes)):\n",
    "        bin_size = BinSizes[gg]\n",
    "        tb = np.arange(min_val, max_val + bin_size, bin_size)\n",
    "    \n",
    "        binM[gg] = np.zeros((nneu, len(tb) - 1), dtype=np.uint8)\n",
    "        number_tests += nneu * (nneu - 1) * (2 * MaxLags[gg] + 1) // 2\n",
    "    \n",
    "        for n in range(nneu):\n",
    "            binM[gg][n, :], _ = np.histogram(padded_spike_times[n][~np.isnan(padded_spike_times[n])], tb)\n",
    "        \n",
    "        assembly = {'bin': [{'n': [], 'bin_edges': tb} for _ in range(len(BinSizes))]}\n",
    "        \n",
    "        if binM[gg].shape[1] - MaxLags[gg] < 100:\n",
    "            print(f'Warning: testing bin size={int_val}. The time series is too short, consider taking a longer portion of spike train or diminish the bin size to be tested')\n",
    "            testit[gg] = 0\n",
    "\n",
    "    # Detecting First Order Assemblies\n",
    "    print('order 1')\n",
    "    Assemblies_all_orders = []\n",
    "    O = 1\n",
    "    Dc = 100  # length (in # bins) of the segments in which the spike train is divided to compute #abba variance (parameter k).\n",
    "\n",
    "    assembly_selected_xy = []\n",
    "    p_values = []\n",
    "\n",
    "    # First order assembly\n",
    "    print('order 1')\n",
    "    assembly_selected_xy = []\n",
    "    p_values = []\n",
    "        \n",
    "    # Prepare arguments for parallel processing\n",
    "    pair_args = [\n",
    "            (w1, w2, binM, MaxLags, BinSizes, Dc, ref_lag)\n",
    "            for w1, w2 in combinations(range(nneu), 2)\n",
    "        ]\n",
    "        \n",
    "    # Use multiprocessing to parallelize the computation\n",
    "    with mp.Pool() as pool:\n",
    "            results = pool.map(process_pair, pair_args)\n",
    "        \n",
    "    # Process the results\n",
    "    for result, p_value in results:\n",
    "        if result is not None:\n",
    "            assembly_selected_xy.append(result)\n",
    "            p_values.append(p_value)\n",
    "        \n",
    "    if not assembly_selected_xy:\n",
    "        raise ValueError(\"No valid assemblies found. Check the input data and parameters.\")\n",
    "        \n",
    "    assembly_selected = assembly_selected_xy\n",
    "        \n",
    "    # Holm-Bonferroni correction\n",
    "    x = np.arange(1, len(p_values) + 1)\n",
    "    p_values = np.sort(p_values)\n",
    "    p_values_alpha = alph / (number_tests + 1 - x)\n",
    "        \n",
    "    ANfo = np.zeros((nneu, nneu))\n",
    "        \n",
    "    # Initialize HBcorrected_p before using it\n",
    "    aus = np.where((p_values - p_values_alpha) < 0)[0]\n",
    "    HBcorrected_p = 0 if len(aus) == 0 else p_values[aus[-1]]\n",
    "        \n",
    "    for oo in range(len(assembly_selected) - 1, -1, -1):\n",
    "        if assembly_selected[oo]['pr'][-1] > HBcorrected_p:\n",
    "            assembly_selected.pop(oo)\n",
    "        else:\n",
    "            ANfo[assembly_selected[oo]['elements'][0], assembly_selected[oo]['elements'][1]] = 1\n",
    "        \n",
    "    Assemblies_all_orders = [assembly_selected]\n",
    "\n",
    "    # Detecting Higher Order Assemblies\n",
    "    # Higher orders\n",
    "    Oincrement = 1\n",
    "    while Oincrement and O < (O_th - 1):\n",
    "        O += 1\n",
    "        print(f'order {O}')\n",
    "        Oincrement = 0\n",
    "        assembly_selected_aus = []\n",
    "        xx = 0  # Python uses 0-based indexing\n",
    "        \n",
    "        for w1 in range(len(assembly_selected)):\n",
    "            # bin at which to test w1\n",
    "            ggg = BinSizes.index(assembly_selected[w1]['bin'])\n",
    "        \n",
    "            # element to test with w1\n",
    "            w1_elements = assembly_selected[w1]['elements']\n",
    "            w2_to_test = np.where(ANfo[w1_elements, :] == 1)[1]  # Using numpy for efficiency\n",
    "            w2_to_test = w2_to_test[~np.isin(w2_to_test, w1_elements)]  # Remove elements already in the assembly\n",
    "            w2_to_test = np.unique(w2_to_test)\n",
    "        \n",
    "            for w2 in w2_to_test:\n",
    "                spikeTrain2 = binM[ggg][w2, :]\n",
    "                assemblybin_aus = test_pair_ref(assembly_selected[w1], spikeTrain2, w2, MaxLags[ggg], Dc, ref_lag)\n",
    "                p_values.append(assemblybin_aus['pr'][-1])\n",
    "                number_tests += 2 * MaxLags[ggg] + 1\n",
    "                if assemblybin_aus['pr'][-1] < HBcorrected_p:\n",
    "                    assembly_selected_aus.append(assemblybin_aus)\n",
    "                    assembly_selected_aus[-1]['bin'] = BinSizes[ggg]\n",
    "                    xx += 1\n",
    "                    Oincrement = 1\n",
    "\n",
    "        if Oincrement:\n",
    "            # Pruning within the same size\n",
    "            na = len(assembly_selected_aus)\n",
    "            nelement = len(assembly_selected_aus[0]['elements'])\n",
    "            selection = np.full((na, nelement + 2), np.nan)\n",
    "            assembly_final = [None] * na\n",
    "            nns = 0\n",
    "\n",
    "            for i in range(na):\n",
    "                elem = sorted(assembly_selected_aus[i]['elements'])\n",
    "                ism = np.all(selection[:, :nelement] == elem, axis=1)\n",
    "                if not np.any(ism):\n",
    "                    assembly_final[nns] = assembly_selected_aus[i]\n",
    "                    selection[nns, :nelement] = elem\n",
    "                    selection[nns, nelement] = assembly_selected_aus[i]['pr'][-1]\n",
    "                    selection[nns, nelement + 1] = i\n",
    "                    nns += 1\n",
    "                else:\n",
    "                    indx = np.where(ism)[0][0]\n",
    "                    if selection[indx, nelement] > assembly_selected_aus[i]['pr'][-1]:\n",
    "                        assembly_final[indx] = assembly_selected_aus[i]\n",
    "                        selection[indx, nelement] = assembly_selected_aus[i]['pr'][-1]\n",
    "                        selection[indx, nelement + 1] = i\n",
    "\n",
    "            assembly_final = [a for a in assembly_final if a is not None]\n",
    "            assembly_selected = assembly_final\n",
    "            Assemblies_all_orders.append(assembly_final)\n",
    "\n",
    "        # Holm-Bonferroni correction\n",
    "        x = np.arange(1, len(p_values) + 1)\n",
    "        p_values = np.sort(p_values)\n",
    "        p_values_alpha = alph / (number_tests + 1 - x)\n",
    "        aus = np.where((p_values - p_values_alpha) < 0)[0]\n",
    "        HBcorrected_p = 0 if len(aus) == 0 else p_values[aus[-1]]\n",
    "\n",
    "        for o in range(len(Assemblies_all_orders)):\n",
    "            Assemblies_all_orders[o] = [a for a in Assemblies_all_orders[o] if a['pr'][-1] <= HBcorrected_p]\n",
    "\n",
    "        # Pruning between different assembly sizes\n",
    "        Element_template = []\n",
    "        for assembly in Assemblies_all_orders[-1]:\n",
    "            Element_template.append(assembly['elements'])\n",
    "\n",
    "        for o in range(len(Assemblies_all_orders) - 2, -1, -1):\n",
    "            new_assemblies = []\n",
    "            for assembly in Assemblies_all_orders[o]:\n",
    "                if not any(set(assembly['elements']).issubset(set(template)) for template in Element_template):\n",
    "                    new_assemblies.append(assembly)\n",
    "                    Element_template.append(assembly['elements'])\n",
    "            Assemblies_all_orders[o] = new_assemblies\n",
    "\n",
    "        # Reformat dividing by bins\n",
    "        assembly = {'bin': [{} for _ in range(len(BinSizes))]}\n",
    "        for o, order_assemblies in enumerate(Assemblies_all_orders):\n",
    "            for oo, a in enumerate(order_assemblies):\n",
    "                bx = BinSizes.index(a['bin'])\n",
    "                if 'n' not in assembly['bin'][bx]:\n",
    "                    assembly['bin'][bx]['n'] = []\n",
    "                assembly['bin'][bx]['n'].append(a)\n",
    "\n",
    "        # Remove empty bins\n",
    "        assembly['bin'] = [b for b in assembly['bin'] if b]\n",
    "\n",
    "        # Add parameters to assembly\n",
    "        assembly['parameters'] = {\n",
    "            'alph': alph,\n",
    "            'Dc': Dc,\n",
    "            'No_th': No_th,\n",
    "            'O_th': O_th,\n",
    "            'bytelimit': bytelimit,\n",
    "            'ref_lag': ref_lag\n",
    "        }\n",
    "\n",
    "    # Return statement inside the function\n",
    "    As_across_bins, As_across_bins_index = assemblies_across_bins(assembly, BinSizes)\n",
    "    return As_across_bins, As_across_bins_index, assembly, Assemblies_all_orders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythoncadopti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
